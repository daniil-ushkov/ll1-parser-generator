package generator

import (
	"bytes"
	"fmt"
	"ll1-parser-generator/grammar"
	"os"
	"path/filepath"
	"strings"
)

func (ctx *Context) GenerateAstParserGo() error {
	var err error
	ctx.file, err = os.Create(filepath.Join(ctx.Out, "ast_parser.go"))
	if err != nil {
		return err
	}
	defer closeFmt(ctx.file)

	err = ctx.generateAstParserHeader()
	if err != nil {
		return err
	}

	err = ctx.generateAstParser()
	if err != nil {
		return err
	}

	return nil
}

func (ctx *Context) generateAstParserHeader() error {
	_, err := ctx.file.WriteString(fmt.Sprintf(`
// Code generated by daniil-ushkov LL(1) parser generator; DO NOT EDIT.
package %s

import (
	"fmt"
	"strconv"
)

func __fmt_unused_import_ignore() {
	fmt.Print()
}

func __strconv_unused_import_ignore() {
	_, _ = strconv.Atoi("12345")
}
`, ctx.Package))
	return err
}

func (ctx *Context) generateAstParser() error {
	_, err := ctx.file.WriteString(`
type Parser struct {
	Lexer Lexer
}
`)
	if err != nil {
		return err
	}

	_, err = ctx.file.WriteString(fmt.Sprintf(`
func (__p *Parser) Parse() (Ast, error) {
	return __p.Parse%s()
}
`, ctx.Grammar.Desc.StartRule.Name))
	if err != nil {
		return err
	}

	_, nonTerminals := ctx.extractSymbols()
	for nonTerminal := range nonTerminals {
		err = ctx.generateAstParseFunction(nonTerminal)
		if err != nil {
			return err
		}
	}

	return err
}

const AstParseFunctionTmpl = `
func (p *Parser) Parse{{.NonTerminal}}() (Ast, error) {
	var ast Ast = &AstNonTerminal{NonTerminal: {{.NonTerminal}}}
	var tmpAst Ast
	var err error

	_ = ast
	_ = tmpAst
	_ = err

	switch p.Lexer.Get().Symbol {
		{{.SwitchBody}}
	default:
		{{.DefaultBody}}
	}

	return ast, nil
}
`

type AstParseFunctionModel struct {
	NonTerminal string
	SwitchBody  string
	DefaultBody string
}

func (ctx *Context) generateAstParseFunction(nonTerminal grammar.NonTerminal) error {
	rules := ctx.extractParserRules(nonTerminal)

	switchBodyBuf := bytes.Buffer{}
	for _, rule := range rules {
		stripedRule := rule.Striped()

		terminals := ctx.Grammar.GetFirst(stripedRule)
		if terminals.Has(grammar.EPS) {
			terminals.Erase(grammar.EPS)
			terminals.AddAll(ctx.Grammar.Follow[rule.NonTerminal])
		}

		switchBodyBuf.WriteString(generateCaseAst(terminals, rule))
	}

	executed, _ := execute(AstParseFunctionTmpl, AstParseFunctionModel{
		NonTerminal: nonTerminal.Name,
		SwitchBody:  switchBodyBuf.String(),
		DefaultBody: `return nil, fmt.Errorf("unexpected symbol: %s, rest: (%s, \"%s\")", p.Lexer.Get().Symbol.String(), p.Lexer.Next.Symbol.String(), p.Lexer.Input)`,
	})

	_, err := ctx.file.WriteString(executed)

	return err
}

func generateCaseAst(terminals grammar.TerminalSet, parserRule grammar.ParserRule) string {
	caseBodyBuf := bytes.Buffer{}

	var terminalsNames []string
	for terminal := range terminals {
		terminalsNames = append(terminalsNames, terminal.Name)
	}

	caseBodyBuf.WriteString(fmt.Sprintf("case %s:", strings.Join(terminalsNames, ", ")))

	for _, item := range parserRule.Rule {
		switch item1 := item.(type) {
		case grammar.TerminalParserRuleItem:
			caseBodyBuf.WriteString(terminalSwitchFragmentAst(item1))
		case grammar.NonTerminalParserRuleItem:
			caseBodyBuf.WriteString(nonTerminalSwitchFragmentAst(item1))
		}
	}

	return caseBodyBuf.String()
}

func terminalSwitchFragmentAst(terminalRuleItem grammar.TerminalParserRuleItem) string {
	return fmt.Sprintf(`
if p.Lexer.Get().Symbol != %[1]s {
	return nil, fmt.Errorf("%[1]s expected")
}
ast.AddChild(&AstTerminal{Token: p.Lexer.Get()})
p.Lexer.MoveNext()
`, terminalRuleItem.Terminal.Name)
}

func nonTerminalSwitchFragmentAst(nonTerminalParserRuleItem grammar.NonTerminalParserRuleItem) string {
	return fmt.Sprintf(`
tmpAst, err = p.Parse%[1]s()
if err != nil {
	return nil, err
}
ast.AddChild(tmpAst)
`, nonTerminalParserRuleItem.NonTerminal.Name)
}
