package generator

import (
	"bytes"
	"fmt"
	"os"
	"path/filepath"
)

const LexerGoTmpl = `
// Code generated by daniil-ushkov LL(1) parser generator; DO NOT EDIT.
package {{.Package}}

import "regexp"

type Token struct {
	Symbol Terminal
	Lexeme string
}

type Rule struct {
	Symbol Terminal
	Regexp *regexp.Regexp
}

type Lexer struct {
	Rules []Rule
	Skip  []*regexp.Regexp

	Cur  *Token
	Next *Token

	Input string
}

func NewLexer(input string) Lexer {
	{{.RegexpCompilation}}

	lex := Lexer{
		Rules: []Rule{
			{{.RuleRegexps}}
		},
		Skip: []*regexp.Regexp{
			{{.SkipRegexps}}
		},
		Input: input,
	}

	lex.Cur = lex.nextImpl()
	lex.Next = lex.nextImpl()

	return lex
}

func (l *Lexer) HasNext() bool {
	return !(l.Cur.Symbol == EOF && l.Next.Symbol == EOF)
}

func (l *Lexer) MoveNext() {
	l.Cur = l.Next
	l.Next = l.nextImpl()
}

func (l *Lexer) nextImpl() *Token {
	for {
		noWs := true
		for _, skip := range l.Skip {
			inds := skip.FindStringIndex(l.Input)
			if inds != nil && inds[0] == 0 {
				l.Input = l.Input[inds[1]:]
				noWs = false
			}
		}
		if noWs {
			break
		}
	}

	if l.Input == "" {
		return &Token{Symbol: EOF, Lexeme: ""}
	}

	for _, rule := range l.Rules {
		inds := rule.Regexp.FindStringIndex(l.Input)
		if inds != nil && inds[0] == 0 {
			res := &Token{Symbol: rule.Symbol, Lexeme: l.Input[inds[0]:inds[1]]}
			l.Input = l.Input[inds[1]:]
			return res
		}
	}

	return nil
}

func (l *Lexer) Get() Token {
	return *l.Cur
}
`

type LexerGoModel struct {
	Package           string
	RegexpCompilation string
	RuleRegexps       string
	SkipRegexps       string
}

func (ctx *Context) GenerateLexerGo() error {
	var err error
	ctx.file, err = os.Create(filepath.Join(ctx.Out, "lexer.go"))
	if err != nil {
		return err
	}
	defer closeFmt(ctx.file)

	executed, _ := execute(LexerGoTmpl, ctx.createLexerGoModel())

	_, err = ctx.file.WriteString(executed)
	if err != nil {
		return err
	}

	return nil
}

func (ctx *Context) createLexerGoModel() LexerGoModel {
	regexpCompilationBuf := bytes.Buffer{}
	ruleRegexpsBuf := bytes.Buffer{}

	for _, rule := range ctx.Grammar.Desc.LexerRules {
		regexpCompilationBuf.WriteString(fmt.Sprintf("%sreg, _ := regexp.Compile(%s)\n", rule.Terminal.Name, rule.Regexp))
		ruleRegexpsBuf.WriteString(fmt.Sprintf("{Symbol: %[1]s, Regexp: %[1]sreg},\n", rule.Terminal.Name))
	}

	skipRegexpsBuf := bytes.Buffer{}
	for i, rule := range ctx.Grammar.Desc.SkipRules {
		regexpCompilationBuf.WriteString(fmt.Sprintf("skip%d, _ := regexp.Compile(%s)\n", i, rule.Regexp))
		skipRegexpsBuf.WriteString(fmt.Sprintf("skip%d,\n", i))
	}

	return LexerGoModel{
		Package:           ctx.Package,
		RegexpCompilation: regexpCompilationBuf.String(),
		RuleRegexps:       ruleRegexpsBuf.String(),
		SkipRegexps:       skipRegexpsBuf.String(),
	}
}
